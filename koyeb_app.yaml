# Koyeb GPU App Configuration
# Northeastern University Chatbot - A100 GPU Optimized

name: northeastern-gpu-chatbot
services:
  - name: gpu-chatbot-api
    source:
      type: github
      repository: SandaAbhishekSagar/Lambda_MGEN_GPT
      branch: main
    ports:
      - port: 8000
        target_port: 8000
        protocol: http
    env:
      - name: OPENAI_API_KEY
        value: "your_openai_api_key_here"
      - name: CHROMA_API_KEY
        value: "ck-4RLZskGk7sxLbFNvMZCQY4xASn4WPReJ1W4CSf9tvhUW"
      - name: CHROMA_TENANT
        value: "28757e4a-f042-4b0c-ad7c-9257cd36b130"
      - name: CHROMA_DATABASE
        value: "newtest"
      - name: CHROMA_HOST
        value: "localhost"
      - name: CHROMA_PORT
        value: "8000"
      # GPU optimization environment variables
      - name: CUDA_VISIBLE_DEVICES
        value: "0"
      - name: PYTORCH_CUDA_ALLOC_CONF
        value: "max_split_size_mb:512"
      - name: TOKENIZERS_PARALLELISM
        value: "false"
    regions:
      - fra  # Frankfurt region for GPU availability
    instance_type: gpu-1  # GPU instance for A100
    scaling:
      min_instances: 0
      max_instances: 2  # Limit for cost optimization
    resources:
      cpu: 4
      memory: 16Gi
      gpu: 1
