# RunPod Configuration for Northeastern University Chatbot
# Optimized for GPU acceleration and fast response times

name: northeastern-university-chatbot
description: "GPU-accelerated RAG chatbot for Northeastern University with 5-8 second response times"

# Docker configuration
docker:
  image: "your-docker-username/northeastern-chatbot:v1.0.0"
  platform: "linux/amd64"

# GPU configuration for optimal performance
gpu:
  type: "RTX 4090"  # or "A100", "V100" based on availability
  memory: "24GB"    # Minimum 16GB recommended
  count: 1

# Environment variables (set these in RunPod console)
environment:
  OPENAI_API_KEY: "your_openai_api_key_here"
  CHROMA_API_KEY: "your_chroma_api_key_here"
  CHROMA_HOST: "your_chroma_host_here"
  CHROMA_PORT: "8000"
  CHROMA_TENANT: "default_tenant"
  CHROMA_DATABASE: "default_database"

# Performance settings
performance:
  workers: 1
  timeout: 300  # 5 minutes
  max_concurrent: 5
  cold_start_timeout: 60

# Optimization settings
optimization:
  enable_gpu_acceleration: true
  enable_caching: true
  cache_ttl: 300  # 5 minutes
  max_collections_search: 50
  max_documents_per_query: 8
  concurrent_searches: 8

# Monitoring
monitoring:
  enable_logging: true
  log_level: "INFO"
  enable_metrics: true