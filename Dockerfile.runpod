# RunPod Serverless Dockerfile
# GPU-optimized for Northeastern University Chatbot

FROM runpod/pytorch:2.1.0-py3.10-cuda12.1.0-devel

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    wget \
    curl \
    vim \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY runpod_requirements.txt requirements.txt

# Install Python dependencies
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Copy application files
COPY runpod_handler.py .
COPY services/ ./services/

# Set Python path
ENV PYTHONPATH=/app:$PYTHONPATH

# Environment variables
ENV PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
ENV TRANSFORMERS_CACHE=/runpod-volume/transformers-cache
ENV HF_HOME=/runpod-volume/huggingface

# Create cache directories
RUN mkdir -p /runpod-volume/transformers-cache /runpod-volume/huggingface

# RunPod handler
CMD ["python", "-u", "runpod_handler.py"]

